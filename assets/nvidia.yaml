---

# models
- type: model
  name: Megatron-LM
  organization: NVIDIA
  description: Megatron-LM is an autoregressive language model
  created_date:
    value: 2021-04-09
    explanation: The date the paper for the 1 trillion parameter model was published
  url: https://arxiv.org/abs/2104.04473
  model_card: none
  modality: text (English)
  analysis: ''
  size: 1000B parameters (dense model)
  dependencies: []
  training_emissions: unknown
  training_time: 84 days
  training_hardware: 3072 A100 GPUs
  quality_control: unknown
  access:
    value: closed
    explanation: >
      Neither the 8.3B parameter model trained to convergence nor the 1 trillion
      paramter model is available for download
  license:
    value: unknown
    explanation: >
      The asset isn't released, and hence the license is unknown.
  intended_uses: none
  prohibited_uses: none
  monitoring: none
  feedback: none

- type: dataset
  name: MineDojo
  organization: NVIDIA
  description: ''
  created_date: 2022-06-17
  url: https://arxiv.org/abs/2206.08853
  datasheet: ''
  modality: Videos, Text
  size: 730k videos, 6k Wikipedia pages, 340k reddit posts
  sample: []
  analysis: ''
  dependencies: [YouTube, Wikipedia, Reddit]
  included: ''
  excluded: ''
  quality_control: ''
  access: open
  license: MIT
  intended_uses: ''
  prohibited_uses: ''
  monitoring: ''
  feedback: ''

- type: dataset
  name: VIMA dataset
  organization: NVIDIA, Stanford
  description: ''
  created_date: 2022-10-06
  url: https://vimalabs.github.io/
  datasheet: ''
  modality: text and image
  size: 200M parameters (dense model)
  sample: []
  analysis: ''
  dependencies: [T5, Mask R-CNN, VIMA dataset]
  included: ''
  excluded: ''
  quality_control: ''
  access: open
  license: MIT
  intended_uses: ''
  prohibited_uses: ''
  monitoring: ''
  feedback: ''

- type: model
  name: VIMA
  organization: NVIDIA, Stanford
  description: ''
  created_date: 2022-10-06
  url: https://vimalabs.github.io/
  model_card: ''
  modality: Simulation
  analysis: ''
  size: 650K successful trajectories
  dependencies: []
  training_emissions: ''
  training_time: ''
  training_hardware: ''
  quality_control: ''
  access: open
  license: MIT
  intended_uses: ''
  prohibited_uses: ''
  monitoring: ''
  feedback: ''


- type: model
  name: Fastpitch
  organization: NVIDIA
  description: >
    FastPitch is a fully-parallel text-to-speech model based on FastSpeech, conditioned on
    fundamental frequency contours. The model predicts pitch contours during inference. 
    By altering these predictions, the generated speech can be more expressive, better match
    the semantic of the utterance, and in the end more engaging to the listener.
    FastPitch is based on a fully-parallel Transformer architecture, with a much higher real-time 
    factor than Tacotron2 for the mel-spectrogram synthesis of a typical utterance. It uses an 
    unsupervised speech-text aligner.
  created_date:
    value: NA
    explanation: The model creation date is unknown.
  url: NA
  model_card: https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/tts_en_fastpitch
  modality: Text to Speech
  size: 45 Million Parameters
  analysis: ''
  dependencies: 
    - LJSpeech dataset sampled at 22050 Hz
  training_emissions: ''
  training_time: NA
  training_hardware: NA
  quality_control: ''
  access: open
  license:
    value: NGC
    explanation: NA
  intended_uses:
    value: unknown
    explanation: >
      This model is intended for expressive speech generation with real-time generation
  prohibited_uses: >
    This checkpoint only works well with vocoders that were trained on 22050Hz data.
    Otherwise, the generated audio may be scratchy or choppy-sounding.
  monitoring: unknown
  feedback: unknown


- type: model
  name: HIFIGAN
  organization: nvidia
  description: >
    HiFi-GAN consists of one generator and two discriminators: multi-scale and
    multi-period discriminators. The generator and discriminators are trained adversarially,
    along with two additional losses for improving training stability and model performance.
  created_date:
    value: NA
    explanation: NA
  url: NA
  model_card: https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/tts_hifigan
  modality: Text to Speech 
  size: 85 Million Parameters
  analysis: ''
  dependencies: 
    - LJSpeech dataset sampled at 22050Hz
  training_emissions: ''
  training_time: NA
  training_hardware: NA
  quality_control: ''
  access: open
  license:
    value: NGC
    explanation: NA
  intended_uses:
    value: unknown
    explanation: >
      This model is intended for expressive speech generation with real-time generation
  prohibited_uses: >
    If the spectrogram generator model (example FastPitch) is trained/finetuned on
    new speaker's data it is recommended to finetune HiFi-GAN also. HiFi-GAN shows 
    improvement using synthesized mel spectrograms, so the first step is to generate 
    mel spectrograms with our finetuned FastPitch model to use as input to finetune HiFiGAN.
  monitoring: unknown
  feedback: unknown


- type: model
  name: NMT Multilingual De/Es/Fr En Transformer12x2
  organization: NVIDIA
  description: >
    The model is based on Transformer "Big" architecture originally presented in "Attention Is All You Need" paper. 
    In this particular instance, the model has 12 layers in the encoder and 2 layers in the decoder. It is using 
    SentencePiece tokenizer.
  created_date:
    value: Unknown
    explanation: NA
  url: NA
  model_card: https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/mnmt_deesfr_en_transformer12x2
  modality: Text Translation
  size: unknown
  analysis: ''
  dependencies: 
    - http://www.statmt.org/europarl/v10/training/europarl-v10.de-en.tsv.gz
    - http://www.statmt.org/wmt13/training-parallel-commoncrawl.tgz
    - https://s3.amazonaws.com/web-language-models/paracrawl/release7.1/en-de.txt.gz
    - http://data.statmt.org/news-commentary/v15/training/news-commentary-v15.de-en.tsv.gz
  training_emissions: ''
  training_time: ''
  training_hardware: ''
  quality_control: ''
  access: open
  license:
    value: NGC
    explanation: NA
  intended_uses:
    value: unknown
    explanation: >
      Multi lingual translation for French, German, Spanish languages to English.
  prohibited_uses: unknown
  monitoring: unknown
  feedback: unknown



- type: model
  name: RIVA Conformer ASR English en-US
  organization: NVIDIA
  description: >
    Conformer-CTC (around 120M parameters) is trained on ASRSet with
    over 16500 hours of English(en-US) speech. The model transcribes speech in lower
    case english alphabet along with spaces and apostrophes'
  created_date:
    value: Unknown
    explanation: NA
  url: NA
  model_card: https://catalog.ngc.nvidia.com/orgs/nvidia/teams/riva/models/speechtotext_en_us_conformer
  modality: Speech to Text
  size: 30 Million Parameters
  analysis: ''
  dependencies: 
    - Librispeech 960 hours of English speech
    - Fisher Corpus
    - Switchboard-1 Dataset
    - WSJ-0 and WSJ-1
    - National Speech Corpus (Part 1, Part 6)
    - VCTK
    - VoxPopuli (EN)
    - Europarl-ASR (EN)
    - Multilingual Librispeech (MLS EN) - 2,000 hours subset
    - Mozilla Common Voice (v7.0)
  training_emissions: ''
  training_time: ''
  training_hardware: ''
  quality_control: ''
  access: open
  license:
    value: NVIDIA RIVA LICENSE
    explanation: NA
  intended_uses:
    value: unknown
    explanation: >
      This model can be used for english speech transcription with world level
      accurate timestamps
  prohibited_uses: >
    Since this model was trained on publically available speech datasets, the performance
    of this model might degrade for speech which includes technical terms, or vernacular that 
    the model has not been trained on. The model might also perform worse for accented speech.
  monitoring: unknown
  feedback: unknown

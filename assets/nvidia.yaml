---

# models
- type: model
  name: Megatron-LM
  organization: NVIDIA
  description: Megatron-LM is an autoregressive language model
  created_date:
    value: 2021-04-09
    explanation: The date the paper for the 1 trillion parameter model was published
  url: https://arxiv.org/abs/2104.04473
  model_card: none
  modality: text (English)
  analysis: ''
  size: 1000B parameters (dense model)
  dependencies: []
  training_emissions: unknown
  training_time: 84 days
  training_hardware: 3072 A100 GPUs
  quality_control: unknown
  access:
    value: closed
    explanation: >
      Neither the 8.3B parameter model trained to convergence nor the 1 trillion
      paramter model is available for download
  license:
    value: unknown
    explanation: >
      The asset isn't released, and hence the license is unknown.
  intended_uses: none
  prohibited_uses: none
  monitoring: none
  feedback: none

- type: dataset
  name: MineDojo
  organization: NVIDIA
  description: ''
  created_date: 2022-06-17
  url: https://arxiv.org/abs/2206.08853
  datasheet: ''
  modality: Videos, Text
  size: 730k videos, 6k Wikipedia pages, 340k reddit posts
  sample: []
  analysis: ''
  dependencies: [YouTube, Wikipedia, Reddit]
  included: ''
  excluded: ''
  quality_control: ''
  access: open
  license: MIT
  intended_uses: ''
  prohibited_uses: ''
  monitoring: ''
  feedback: ''

- type: dataset
  name: VIMA dataset
  organization: NVIDIA, Stanford
  description: ''
  created_date: 2022-10-06
  url: https://vimalabs.github.io/
  datasheet: ''
  modality: text and image
  size: 200M parameters (dense model)
  sample: []
  analysis: ''
  dependencies: [T5, Mask R-CNN, VIMA dataset]
  included: ''
  excluded: ''
  quality_control: ''
  access: open
  license: MIT
  intended_uses: ''
  prohibited_uses: ''
  monitoring: ''
  feedback: ''

- type: model
  name: VIMA
  organization: NVIDIA, Stanford
  description: ''
  created_date: 2022-10-06
  url: https://vimalabs.github.io/
  model_card: ''
  modality: Simulation
  analysis: ''
  size: 650K successful trajectories
  dependencies: []
  training_emissions: ''
  training_time: ''
  training_hardware: ''
  quality_control: ''
  access: open
  license: MIT
  intended_uses: ''
  prohibited_uses: ''
  monitoring: ''
  feedback: ''


- type: model
  name: Fastpitch
  organization: nvidia
  description: This model converts text to spectrogram.
  created_date:
    value: NA
    description: NA
  url: NA
  model_card: NA
  modality: Text (English)
  size: 177.73 MB
  analysis: ''
  dependencies: ''
  training_emissions: ''
  training_time: NA
  training_hardware: NA
  quality_control: ''
  access: open
  license:
    value: NGC
    explanation: NA
  intended_uses:
    value: text to speech
    explanation: >
      NA
  prohibited_uses: unknown
  monitoring: unknown
  feedback: unknown


- type: model
  name: HIFIGAN
  organization: nvidia
  description: This model converts spectrogram to speech.
  created_date:
    value: NA
    description: NA
  url: NA
  model_card: NA
  modality: Text (English)
  size: 300 MB
  analysis: ''
  dependencies: ''
  training_emissions: ''
  training_time: NA
  training_hardware: NA
  quality_control: ''
  access: open
  license:
    value: NGC
    explanation: NA
  intended_uses:
    value: unknown
    explanation: >
      NA
  prohibited_uses: unknown
  monitoring: unknown
  feedback: unknown


- type: model
  name: NMT Multilingual De/Es/Fr En Transformer12x2
  organization: NVIDIA
  description: ' This model can be used for translating text in source language (De/Es/Fr)
    to a text in target language (En).'
  created_date:
    value: Unknown
    description: NA
  url: NA
  model_card: https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/mnmt_deesfr_en_transformer12x2
  modality: NA
  size: 1002.75 MB
  analysis: ''
  dependencies: ''
  training_emissions: ''
  training_time: ''
  training_hardware: ''
  quality_control: ''
  access: open
  license:
    value: NGC
    explanation: NA
  intended_uses:
    value: unknown
    explanation: >
      NA
  prohibited_uses: unknown
  monitoring: unknown
  feedback: unknown



- type: model
  name: RIVA Conformer ASR English en-US
  organization: NVIDIA
  description: ' Conformer-CTC (around 120M parameters) is trained on ASRSet with
    over 16500 hours of English(en-US) speech. The model transcribes speech in lower
    case english alphabet along with spaces and apostrophes'
  created_date:
    value: Unknown
    description: NA
  url: NA
  model_card: https://catalog.ngc.nvidia.com/orgs/nvidia/teams/riva/models/speechtotext_en_us_conformer
  modality: NA
  size: 329.96 MB
  analysis: ''
  dependencies: ''
  training_emissions: ''
  training_time: ''
  training_hardware: ''
  quality_control: ''
  access: open
  license:
    value: NVIDIA RIVA LICENSE
    explanation: NA
  intended_uses:
    value: unknown
    explanation: >
      NA
  prohibited_uses: unknown
  monitoring: unknown
  feedback: unknown
